{"name":"Sky Krauthamer","tagline":"I'm a Designer, Developer, HCI Researcher, Roboticist, Fabricator","body":"# Various Projects\r\nCheck for the youtube links if you're a visual person. If any of these seem too technical, boring, or interesting let me know please. kkrautha@andrew.cmu.edu\r\n\r\n## Six Speed Suzy\r\n### Hard Working yet Lazy Susan\r\n\r\n[Video: Scanning Contents](https://youtu.be/wCqprqAEAnY)\r\n\r\n**Problem**\r\nI along with the other members of the Urban Design Build Studio, were tasked with the challenge to re-design the modern kitchen such that it was more accessible to individuals with impaired movement. Because cabinets and cupboards are conventionally lower or higher than the kitchen counter, they are hard to access even for people without disabilities. I had the idea to construct a cabinet or pantry with a single point of entry to a modular storage space. Because the program works closely with \"Construction Junction\" (CJ), we had the opportunity to freely use their recycled materials for the build.\r\n\r\n**Solution**\r\nWhat did we find at Construction Junction? Endless lazy susans. What is a lazy susan? You know that cabinet in the corner of your kitchen that nobody ever uses, where you store kitchen things that you never use?... Our Lazy “Hard Working” Susan system involved motorizing the reclaimed lazy susan cabinet.  Motorizing the movement of the rotating shelves allowed us the ability to set up an automated scanning program. This program would turn the shelves a full 360 and take pictures at set intervals.  This allowed us to reconstruct a crude panorama of the items within the lazy susan. Motorizing the lazy susan involved cutting custom gears out of acrylic to fit a timing belt. I built a generator with adjustable parameters such that we could make the gear system fit to any cabinet CJ came across. The timing belt was driven by a stepper motor mounted on the inside of the cabinet.  This motor turned the rotating shelves.  The stepper motor driver was controlled by an attached Arduino that was sent serial messages to handle rotations.\r\n\r\n**Future**\r\nMy original vision for the project was to make the cabinet voice activated. The 3d scanner would run object recognition on the contents of the pantry, and depending on what the user asks for rotate to display that item. However, we only had about 2 weeks...\r\n\r\n## AirSense\r\n### Passive House Air Quality Sensor\r\n\r\n----\r\n\r\n[Video: Casually Generating a Demo](https://youtu.be/WTYR_SBDIa4)\r\n\r\n\r\n**Problem**\r\n> \r\nThe term passive house (Passivhaus in German) refers to a rigorous, voluntary standard for energy efficiency in a building, reducing its ecological footprint. It results in ultra-low energy buildings that require little energy for space heating or cooling.\r\n\r\nDuring my time in the Urban Design Studio I worked on some of the most interesting design and engineering problems I have encountered. Our primary objective was to design and construct actually habitable houses that conform to \"Passive House\" Standards using materials recycled by \"Construction Junction\". The architects on the team had to pay special attention to the \"Envelope\" to optimize for the optimal atmospheric pressure to minimize unwanted heat exchange. While researching common problems \"Passive Houses\" have, we discovered that the airtight environment can lead to gas and moisture build up within the house. The health impact of these buildups can range from uncomfortable all the way to deadly. These risks can be moderated actions as simple as opening a window, but it is currently quite difficult to tell what the quality of the air actually is.\r\n\r\n**Solution**\r\n\r\nMy team decided to build a system to gather various time based readings to judge and even forecast the overall air quality. The sensor detected ambient light levels, temperature, barometric pressure, relative humidity, levels of carbon monoxide, liquified propane gas, and methane.  This sensor data was collected by the sensor module and posted to a cloud computing service hosted by OpenShift.  This data was then stored in a MongoDB noSQL database in a single values collection. \r\nThe sensor’s ID, value, and timestamp of the post were stored.  These values could then be used for data processing.\r\nOur sensor module was powered by Power over Ethernet, allowing our sensors to be run off a single cable.  This cable carried 5V at an average Amperage of .58A.  This ethernet cable allowed both data and power to be carried over the same cable, allowing setup and sensor placement to be simpler.\r\nBeyond the raw hardware, we created lighting displays to convey the quality of the air as well as potential actions they should take to the home owner. I build a web based interface that displays the time series of the sensor values with smoothed regressions and forecasting for each sensor. I implemented client side code in Javascript that actually runs the time series analysis from the browser, giving the UI a zero footprint on the backend. \r\n\r\n**Tools**\r\n- Hardware & Data\r\n  - Arduino Mega\r\n  - P.O.E. Connectors, Analog & Digital Sensors\r\n  - NodeJS & Express, Python, MongoDB, OpenShift\r\n- User Interface\r\n  - Physical\r\n    - Stereolithographic 3d Printer\r\n    - 80W Laser Cutter\r\n    - Circular Led Light Strip\r\n  - Web Interface\r\n    - AngularJS, Bootstrap, d3\r\n\r\n\r\n## Robin\r\n### DIY 3'x3' CNC Router for under 200$, (No CNC Required)\r\n\r\n----\r\n\r\n[Video: Catch Me If You Can](https://youtu.be/D028NEB1XnU)\r\n\r\nThis is another project I have yet to document on here, but it shows a modular extension to convert the CNC to a flat bed printer. [Video: Flatbread](https://youtu.be/BKf8IJTA3Xk)\r\n\r\n**Problem**: Computer controlled cutting devices have been an important tool in the fabrication process for creating custom parts.  The challenge is that these devices can be very expensive, hard to come by, and are pretty breakable (so good luck). Despite their significance in manufacturing, there are no consumer CNC's for under 700$ yet* that you don't need a CNC to build. Another major issue I have with CNCs is that they are ridiculously sized, often way too large taking up an entire room or too small to cut real material like wood.\r\n\r\n**Solution**: Having never seen or used a CNC I designed and fabricated, from scratch, a CNC that uses raw materials that can be acquired from Home Depot. The additional components: motor controller, motors, and power supply have to be purchased online bringing the current* grand total to 174.77 USD (Which will vary depending on the Dremmel).\r\nTo Solve my complaint about the size, I designed a framing system that can be easily swapped out to resize the cut area. EX: I have a 3'x3' frame right now, but by purchasing new 2'..4'..5' raw metal rods I can change the size to suit my needs.\r\n\r\n**Results**\r\n- They key benefit is that I have designed this device so that it could be manufactured for under $200\r\n- The entire machine can be assembled in under 1 minute and 30 seconds\r\n- The entire machine can be disassembled in under 1 minute\r\n- Disassembled, all of the parts can easily fit into a backpack\r\n- Modular design allows for easy replacement of parts\r\n- Innovative rail system allows for smaller motors, requiring less torque\r\n- Innovative gantry design eliminates need for expensive specialized bearings like linear or V slot\r\n- Uses commodity skateboard wheels, and not very many of them.\r\n \r\n**Tools**\r\n- Fabrication\r\n  - 80W Laser Cutter\r\n  - Autodesk 123D Design\r\n  - Solidworks\r\n  - OpenSCAD \r\n- Development\r\n  - Arduino\r\n  - Nema 17 Stepper Motors\r\n  - Pololu Motor Drivers\r\n  - Arduino\r\n  - G-CODE Motor Control \r\n  - Python Serial G-CODE Streaming Self Built\r\n  \r\n\r\n## Flipper\r\n### IOT Sheet Music\r\n\r\n----\r\n\r\n**Problems**: To master the guitar, you have to memorize lyrics, chords and TABS for literally hundreds of songs songs.  The reality is that many people forget these lyrics when they are playing resulting in a very awkward presentation.  \r\n\r\n**Solution**:  This device streams chords and lyrics from the Internet to a screen that sits at the end of neck of your guitar.  You can quickly download your playlist to the device where it will scroll thru them while you are playing.  Additionally you can set the scroll speed and play the music in real time.   You’ll never forget how to play a song again.  I have submitted this design to a patent company for review.\r\n \r\n**Tools**\r\n- Fabrication\r\n  - 80W Laser Cutter\r\n  - QCAD\r\n- Electronics\r\n  - ESP86266 Wireless Module\r\n  - Lua, Fritzing (Circuit Diagrams)\r\n \r\n\r\n## Internet of Pots\r\n### IOT Soils Management, FaaS Farming as a Service, Buzz\r\n\r\n----\r\n\r\n[Video: Sleepy](https://youtu.be/98BzMbHSvf4)\r\n\r\n[Video: Undocumented Plants](https://youtu.be/KjPBL9TaTDs)\r\n\r\n**Problem**: Growing healthy plants is an art form that requires a sophisticated understanding of soil nutrients, moisture content and light penetration.  Generally when you buy a plant you pour water on it and pray it grows.  \r\n\r\n**Solution**: This application is a IOT spike that you stick into to the soil and it feeds back information on nutrients, soil and light back to a mobile application.  The second phase of this project was creating a drip device that distributes water and nutrients to the plant based on the measurements generated by the sensor.\r\n \r\n**Tools**\r\n- Hardware\r\n  - Bluetooth Serial Transmitter\r\n  - 12V Solenoid valve motor, 12V Pump\r\n  - Analog PH Meter, Soil Moisture Sensor\r\n  - Temperature, Humidity, and Light sensors\r\n  - Arduino Nano\r\n- Development\r\n  - Arduino\r\n  - NodeJS, MongoDB\r\n\r\n## Robo Honey Pot\r\n### Interactive Robot\r\n\r\n----\r\n\r\n[Video: Probably My Favorite](https://youtu.be/ymFxrqigQkQ)\r\n\r\n[Repository](https://github.com/PseudoSky/el-matterdoor)\r\n\r\n**Problem**: One of the revolutions in robotics is the ability to interact with responsive robots that translate human motion into robotic motion.  This ability allows us to monitor physical motion in an environment and either mimic or augment that motion via robotic actions.   \r\n\r\n**Solution**:   This system identifies gestures and creates corresponding electronic motor movements. The system then streams the Kinect gestures over UDP to the motor control system that queues the appropriate controls (Slight Latency Issues). The G-Code based motor controls are then pushed to an Arduino that controls the continuously spinning arms.\r\nI'd like to note that my team spent quite a bit of time designing these bearings from scratch. These bearings allow for circuitry to pass through the center without obstructing the bearings revolutions. Conventionally, these berryings are very expensive (more than 100$ per unit) because special components are needed to support the lateral forces that keep it from toppling. As you can see from the video linked below, our design supports rapid movements from the large wooden arms with minimal friction and lift without back driving our relatively small stepper motors.\r\n \r\n**Tools**\r\n- Development\r\n  - Microsoft Kinect\r\n  - Gesture Training and Recognition\r\n  - Arduino, Grbl, G-Code\r\n  - Lua, C++, NodeJS, Python\r\n  - Express, Mongodb\r\n  - Sketch3 (Architecture Diagram)\r\n- Fabrication\r\n  - Solidworks\r\n  - OpenSCAD\r\n\r\n## RICK\r\n### Robot lock picker\r\n \r\n----\r\n\r\n[Video: Proof Of Concept](https://youtu.be/vMO_8FHJjWE)\r\n\r\n**Problem**: Legally picking lock can be a fun past time.  The revered physicist Richard Feynman spent much of his time while developing the atomic bomb at Los Alamos practicing his safe cracking skills. The pins of a physical lock give off a sound pattern when they are activated.  \r\n\r\n**Solution**: As you pick a lock, this device listens to these sound patterns created by the pins and matches them to the training template of the unique sound emitted by each of the possible pin codes. While listening for the pin response, the board modulates the frequency of a vibration motor attached to the lock pick, increasing in HZ until the pin is successfully bumped up into the open position creating a differentiable sound shift. To recognize the sounds emmitted at (as I call it) the \"time of bump\" (TOB), I wrote an implementation of Dynamic Time Warping (DTW) for the Photon IoT board which enabled supa fast real time signal/sequence matching from the hardware level. It does take some of the fun out picking locks, but is the first machine I've seen that can simultaneously pick and decode locks.\r\n\r\n**Tools**\r\n- I2C, ESP8266 (NodeMCU), Photon, Arduino\r\n- Piezo Electric Contact Microphones, Vibration Motors, OP Amplifiers\r\n- Lock Picks, Osciliscope, Fritzing\r\n- Dynamic Time Warping, Support Vector Machines, Fast Fourier Transforms\r\n- Lua, Python, NodeJs, Max, Processing\r\n\r\n##AFT-Maps\r\n### Navigation For The Visually Impaired \r\n\r\n----\r\n\r\n[Repository](https://github.com/PseudoSky/aft-maps)\r\n\r\n**Problem**: For people that rely on applications like Google Maps and Mapquest, It's hard to imagine navigating without them. Sadly, because we can't yet manipulate mobile displays in three dimensions, the visually impaired have a more difficult time exploring their surroundings. The most common technique to give the visually impaired a mental representation of their physical surroundings is to create with tactile replacements for visual components. Tools do exist to create these maps, but they are expensive, slow, and hard to create.  \r\n\r\n**Solution**: The application I developed, converts images of maps into vectorized laser cut files. After prototyping a user interface with google maps and chrome speech recognition, I proposed it to my two team mates that then built out the web application. \r\nDuring that time I developed new techniques to improve the key qualities of the maps. The three factors I found most important were: how differentiable the paths were through touch, speed of the map produced, and physical form.\r\nThe most successful technique I developed created embossed paths quickly using cut rutines rather than the time intensive and less defined ridges that come with engraving.\r\n \r\n**Results**: Prior to the image processing system and web application, there was no established way for people to go from location or directions on a map to a vectorized format.\r\nUsers simply speak or type the location they're looking for and click download to acquire the file.\r\n\r\nThe cutting techniques that I developed\r\n\r\n- Reduce the material cost of a map by  \r\n\t- 345% compared to plastic 3d printed maps\r\n\t- 820% compared to thermally printed maps\r\n- Reduce the fabrication time (machining time)\r\n\t- 1600% compared to plastic 3d printed maps\r\n\t- 450% compared to thermally printed maps\r\n- Physical Properties\r\n\t- Thermal paper is succeptable to water, heat, rips, rederioration of ridges\r\n\t- 3d prints have very low resolution making it hard to print dense maps as a small object, non flexible materials\r\n\t- There is a wide variety of materials that can be laser cut, materials can be easily acquired, \r\n\r\n**Tools**\r\n- 80W Laser Cutter\r\n- ImageMajick, Potrace\r\n- Google Maps API\r\n- Ruby on Rails, Bash\r\n- QCAD\r\n\r\n## USE\r\n### Ultrasonic Eco Location\r\n\r\n----\r\n\r\n**Problem**: Currently, some visually-impaired individuals can navigate using simulated techniques of echolocation. However, these techniques produce audible clicks that are unsettling and unpleasant to the people around them, therefore making them feel conscious of themselves.\r\nWe propose a solution that allows them to use the existing clicking method, but with ultrasonic frequencies, so that the clicking is not disruptive to the people around them. This technique uses the same mental model that some individuals already use, but makes it more accessible and private.\r\n\r\n**Solution**:  Our device sends out a high frequency sounds that cannot be heard.  The device then receives those signals back and translates them into sound patterns that help the visually map their environment.  The advantage of using high frequency sound is that the process is completely silent. \r\n\r\n**Tools**\r\n- Raspberry Pi\r\n- Python, PureData\r\n- JackAudio, PortAudio\r\n- Fast Fourier Transform \r\n- Sketch3 (Architecture Diagram)\r\n \r\n## Ephemeral\r\n### Cross Platform Message Encryption\r\n\r\n-----\r\n\r\nYou should read the problem then watch this video to really get what it is \r\n[Video: Ephemeral](https://youtu.be/VE-Gi2W7WZk)\r\n\r\n[Repository](https://github.com/PseudoSky/Psypher)\r\n\r\n**Problem**: With the proliferation of public WIFI, your communication is often completely visible to anyone interested in monitoring it.  It is downright scary how easy it is to hijack your text and manipulate or track it.  There are encryption plugins for email, but most people are now communicating via text applications like Whatsapp and Snap Chat. \r\n\r\n**Solution**: This plugin allows the user to easily encrypt data across multiple web applications (Groupme, Slack, Facebook, Gmail) and send it to another user.  The system handles key storage and exchange as well as automatic decryption of text from inside the app. You'll never see encrypted text, unless you turn the plugin off or delete your key. All you have to do to use it is go to facebook open your chat, type your message, hit \"command/ctrl\" and \"e\" and your message will be encrypted in that text box. Once you hit send, because you have your own key, you see the message you were typing.\r\n\r\n- Diffie Hellman, RSA, SHA3\r\n- IndexedDB, Chrome Extension, scjl\r\n\r\n\r\n### IOT Motion Control\r\n\r\n----\r\n\r\n**Problem**: IoT modules offer makers the ability to connect and control projects remotely. Although the new hardware products are used for a great number of things, motor control is very difficult. Many robotics projects rely on low latency signals being sent to motor controls from a central job processor. Current IoT modules do not yet have motor control support for streaming interfaces. \r\n\r\n**Solution**: I designed and implemented three different streaming architectures that allow dynamic low latency motor control. The first two operate using the wireless TCP Protocol, and the third uses UDP. Both of the TCP based systems have a queued command execution buffer to reduce latency. One architecture has the IoT hardware pull future commands from a centralized server, creating an efficient \"on demand\" pipeline. The second pushes commands from a centralized server if there is appropriate space in the IoT hardware's buffer. These solutions are similar to the Pub-Sub style of the UDP protocol, but unlike UDP, they ensure packet delivery (pretty necessary for motor control).\r\n\r\n**Results**\r\n\r\n- Implemented both python and Nodejs \"centralized\" server interfaces\r\n- Very successful implementation, I still use this today\r\n- Very smooth movement as a result of the prefetched commands\r\n- Works on the Photon and ESP8266 IoT modules\r\n- Enables runtime code modification\r\n\r\n**Tools**\r\n\r\n- Arduino, Grbl, G-Code\r\n- Lua, C++, NodeJS, Python\r\n- Express, Mongodb\r\n- Sketch3 (Architecture Diagram)","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}